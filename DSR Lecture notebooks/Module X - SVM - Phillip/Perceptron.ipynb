{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 1024) (11314, 20)\n",
      "Test-data classification report\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.63      0.41      0.50       319\n",
      "           comp.graphics       0.70      0.47      0.56       389\n",
      " comp.os.ms-windows.misc       0.71      0.48      0.58       394\n",
      "comp.sys.ibm.pc.hardware       0.66      0.37      0.47       392\n",
      "   comp.sys.mac.hardware       0.69      0.44      0.54       385\n",
      "          comp.windows.x       0.83      0.48      0.61       395\n",
      "            misc.forsale       0.83      0.67      0.74       390\n",
      "               rec.autos       0.83      0.50      0.62       396\n",
      "         rec.motorcycles       0.93      0.67      0.78       398\n",
      "      rec.sport.baseball       0.80      0.48      0.60       397\n",
      "        rec.sport.hockey       0.86      0.68      0.76       399\n",
      "               sci.crypt       0.93      0.67      0.78       396\n",
      "         sci.electronics       0.50      0.23      0.32       393\n",
      "                 sci.med       0.76      0.47      0.58       396\n",
      "               sci.space       0.88      0.59      0.71       394\n",
      "  soc.religion.christian       0.77      0.59      0.67       398\n",
      "      talk.politics.guns       0.67      0.52      0.59       364\n",
      "   talk.politics.mideast       0.92      0.58      0.71       376\n",
      "      talk.politics.misc       0.59      0.31      0.41       310\n",
      "      talk.religion.misc       0.47      0.22      0.30       251\n",
      "\n",
      "             avg / total       0.76      0.50      0.60      7532\n",
      "\n",
      "Test-data overall accuracy 0.466675517791\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    "import sklearn.feature_extraction.text\n",
    "import sklearn.metrics\n",
    "import sklearn.multiclass\n",
    "import sklearn.svm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#print(np.__version__)\n",
    "#raise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "raise\n",
    "def get_train_test():\n",
    "    train = sklearn.datasets.fetch_20newsgroups(subset='train', remove=('headers'))\n",
    "    test = sklearn.datasets.fetch_20newsgroups(subset='test', remove=('headers'))\n",
    "    return train, test\n",
    "\n",
    "\n",
    "# get the training and test data\n",
    "train, test = get_train_test()\n",
    "\n",
    "# text to vector encoder with maximally 1024 dimensions\n",
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_features=1024, stop_words='english')\n",
    "# newgroup (target) to multi-class label\n",
    "label_encoder = sklearn.preprocessing.LabelBinarizer()\n",
    "\n",
    "# linear svc one vs rest classifier\n",
    "clf = sklearn.multiclass.OneVsRestClassifier(sklearn.svm.LinearSVC())\n",
    "\n",
    "# encode emails in design matrix\n",
    "X = vectorizer.fit_transform(train.data)\n",
    "# encode email newgroups in target matrix\n",
    "y = label_encoder.fit_transform(train.target)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# fit soft-margin linear svms to X, y\n",
    "clf.fit(X, y)\n",
    "\n",
    "# generate a classification report for the test data\n",
    "classif_report = sklearn.metrics.classification_report(\n",
    "    label_encoder.transform(test.target),\n",
    "    clf.predict(vectorizer.transform(test.data)),\n",
    "    target_names=train.target_names\n",
    ")\n",
    "\n",
    "print(\"Test-data classification report\")\n",
    "print(classif_report)\n",
    "\n",
    "test_acc = sklearn.metrics.accuracy_score(\n",
    "    label_encoder.transform(test.target),\n",
    "    clf.predict(vectorizer.transform(test.data))\n",
    ")\n",
    "\n",
    "print(\"Test-data overall accuracy\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron(object):\n",
    "    def __init__(self):\n",
    "        self.theta = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Learns parameter vector self.theta from data X and binary labels y.\n",
    "\n",
    "        y should have -1 for negative class and +1 for positive.\n",
    "        X will be augmented with an intercept term before fitting.\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == y.shape[0]\n",
    "\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.concatenate((X, intercept), axis=1)\n",
    "\n",
    "        self.theta = np.random.randn(X.shape[1], 1)\n",
    "        theta_updated = True\n",
    "        while theta_updated:\n",
    "            theta_updated = False\n",
    "            for i in range(X.shape[0]):\n",
    "                x, yy = X[i, :], y[i]\n",
    "                # if label yy and sign of decision function do not agree\n",
    "                # sample x on wrong side of the hyperplane\n",
    "                if yy * (np.dot(self.theta.T, x.reshape(-1, 1))) <= 0:\n",
    "                    # -y * theta.T * x / d theta = -y*x\n",
    "                    # parameter := parameter - alpha * gradient\n",
    "                    parameter_gradient = -yy * x.reshape(-1, 1)\n",
    "                    self.theta = self.theta - parameter_gradient\n",
    "                    theta_updated = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    def __init__(self):\n",
    "        self.theta = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Learns parameter vector self.theta from data X and binary labels y.\n",
    "\n",
    "        y should have -1 for negative class and +1 for positive.\n",
    "        X will be augmented with an intercept term before fitting.\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == y.shape[0]\n",
    "\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.concatenate((X, intercept), axis=1)\n",
    "        raise NotImplementedError\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
