{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "import sklearn.feature_extraction.text\n",
    "import sklearn.metrics\n",
    "import sklearn.multiclass\n",
    "import sklearn.svm\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "Train dict_keys(['data', 'filenames', 'DESCR', 'target', 'target_names', 'description'])\n",
      "test dict_keys(['data', 'filenames', 'DESCR', 'target', 'target_names', 'description'])\n"
     ]
    }
   ],
   "source": [
    "def get_train_test():\n",
    "    train = sklearn.datasets.fetch_20newsgroups(subset='train', remove=('headers'))\n",
    "    test = sklearn.datasets.fetch_20newsgroups(subset='test', remove=('headers'))\n",
    "    return train, test\n",
    "\n",
    "\n",
    "# get the training and test data\n",
    "train, test = get_train_test()\n",
    "print(type(train))\n",
    "#print(train.shape)\n",
    "print(\"Train\", train.keys())\n",
    "print(\"test\", test.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 20 newsgroups by date dataset\n",
      "All categories:  ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train.description)\n",
    "print(\"All categories: \",train.target_names)\n",
    "print(train.DESCR) # WHAT IS THIS ?\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select only some categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories ['alt.atheism', 'comp.graphics']\n",
      "The data is of type  <class 'list'>  with 1064 samples loaded\n"
     ]
    }
   ],
   "source": [
    "categories_4 = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
    "categories_2 = ['alt.atheism', 'comp.graphics']\n",
    "categories_all = ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
    "categories = categories_2\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "print(\"Categories\", twenty_train['target_names'])\n",
    "print(\"The data is of type \",type(twenty_train['data']), \" with\",len(twenty_train['data']), \"samples loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism\n",
      "comp.graphics\n",
      "comp.graphics\n",
      "comp.graphics\n",
      "alt.atheism\n",
      "comp.graphics\n",
      "comp.graphics\n",
      "comp.graphics\n",
      "comp.graphics\n",
      "comp.graphics\n"
     ]
    }
   ],
   "source": [
    "for t in twenty_train.target[:10]:\n",
    "    print(twenty_train.target_names[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " *** Sample 0, with target category of 0 (alt.atheism) ***\n",
      "\n",
      "The data: From: frank@D012S658.uucp (Frank O'Dwyer)\n",
      "Subject: Re: After 2000 years, can we say that Christian Morality is\n",
      "Organization: Siemens-Nixdorf AG\n",
      "Lines: 28\n",
      "NNTP-Posting-Host: d012s658.ap.mchp.sni.de\n",
      "\n",
      "In article <1993Apr15.125245.12872@abo.fi> MANDTBACKA@FINABO.ABO.FI (Mats Andtbacka) writes:\n",
      "|In <1qie61$fkt@horus.ap.mchp.sni.de> frank@D012S658.uucp writes:\n",
      "|> In article <30114@ursa.bear.com> halat@pooh.bears (Jim Halat) writes:\n",
      "|\n",
      "|> #I'm one of those people who does not know what the word objective means \n",
      "|> #when put next to the word morality.  I assume its an idiom and cannot\n",
      "|> #be defined by its separate terms.\n",
      "|> #\n",
      "|> #Give it a try.\n",
      "|> \n",
      "|> Objective morality is morality built from objective values.\n",
      "|\n",
      "|      \"And these objective values are ... ?\"\n",
      "|Please be specific, and more importantly, motivate.\n",
      "\n",
      "I'll take a wild guess and say Freedom is objectively valuable.  I base\n",
      "this on the assumption that if everyone in the world were deprived utterly\n",
      "of their freedom (so that their every act was contrary to their volition),\n",
      "almost all would want to complain.  Therefore I take it that to assert or\n",
      "believe that \"Freedom is not very valuable\", when almost everyone can see\n",
      "that it is, is every bit as absurd as to assert \"it is not raining\" on\n",
      "a rainy day.  I take this to be a candidate for an objective value, and it\n",
      "it is a necessary condition for objective morality that objective values\n",
      "such as this exist.\n",
      "\n",
      "-- \n",
      "Frank O'Dwyer                                  'I'm not hatching That'\n",
      "odwyer@sse.ie                                  from \"Hens\",  by Evelyn Conlon\n",
      "\n"
     ]
    }
   ],
   "source": [
    "this_sample = 0\n",
    "this_target_int = twenty_train['target'][this_sample]\n",
    "print(\"\\n\\n *** Sample {}, with target category of {} ({}) ***\\n\".format(\n",
    "    this_sample, \n",
    "    this_target_int, \n",
    "    twenty_train.target_names[this_target_int]))\n",
    "print(\"The data:\",twenty_train['data'][this_sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most intuitive way to do so is the bags of words representation:\n",
    "\n",
    "1. assign a fixed integer id to each word occurring in any document of the training set (for instance by building a dictionary from words to integer indices).\n",
    "2. for each document #i, count the number of occurrences of each word w and store it in X[i, j] as the value of feature #j where j is the index of word w in the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a sparse matrix with all possible words as the header. For each sample document, a row is created which lists the count for each word (column). This also means that the word order is lost. \n",
    "\n",
    "Each document is stored as a single row of length N, where N is the total number of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_counts is a Bag of Words sparse matrix: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Number rows (sample documents): 1064 number words (tokens?): 21366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1064, 21366)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "print(\"X_train_counts is a Bag of Words sparse matrix: {}\".format(type(X_train_counts)))\n",
    "print(\"Number rows (sample documents):\", X_train_counts.shape[0], \"number words (tokens?):\", X_train_counts.shape[1])\n",
    "#print()\n",
    "#print(X_train_counts[0,:])\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test query the word - index dictionary\n",
      "algorithm 2853\n",
      "hi 9949\n"
     ]
    }
   ],
   "source": [
    "print(\"Test query the word - index dictionary\")\n",
    "word = 'algorithm'\n",
    "print(word, count_vect.vocabulary_.get(word))\n",
    "word = 'hi'\n",
    "print(word, count_vect.vocabulary_.get(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row, first 10000 entries:\n",
      "  (0, 5756)\t1\n",
      "  (0, 8116)\t1\n",
      "  (0, 9906)\t1\n",
      "  (0, 9777)\t1\n",
      "  (0, 8229)\t1\n",
      "  (0, 5707)\t1\n",
      "  (0, 8814)\t2\n",
      "  (0, 4706)\t1\n",
      "  (0, 6513)\t1\n",
      "  (0, 2445)\t1\n",
      "  (0, 3370)\t3\n",
      "  (0, 4071)\t1\n",
      "  (0, 3889)\t1\n",
      "  (0, 3408)\t2\n",
      "  (0, 5594)\t1\n",
      "  (0, 2872)\t1\n",
      "  (0, 2907)\t2\n",
      "  (0, 5892)\t1\n",
      "  (0, 2550)\t1\n",
      "  (0, 8128)\t2\n",
      "  (0, 6781)\t1\n",
      "  (0, 8131)\t2\n",
      "  (0, 3435)\t1\n",
      "  (0, 3760)\t1\n",
      "  (0, 8946)\t3\n",
      "  :\t:\n",
      "  (0, 5452)\t1\n",
      "  (0, 3815)\t1\n",
      "  (0, 1156)\t1\n",
      "  (0, 8687)\t1\n",
      "  (0, 779)\t1\n",
      "  (0, 3048)\t1\n",
      "  (0, 8630)\t1\n",
      "  (0, 8581)\t2\n",
      "  (0, 2410)\t2\n",
      "  (0, 333)\t1\n",
      "  (0, 324)\t1\n",
      "  (0, 674)\t1\n",
      "  (0, 3354)\t2\n",
      "  (0, 6535)\t2\n",
      "  (0, 3151)\t2\n",
      "  (0, 1078)\t1\n",
      "  (0, 2735)\t1\n",
      "  (0, 5135)\t1\n",
      "  (0, 4697)\t2\n",
      "  (0, 842)\t1\n",
      "  (0, 2730)\t1\n",
      "  (0, 7505)\t2\n",
      "  (0, 6392)\t3\n",
      "  (0, 8925)\t4\n",
      "  (0, 8991)\t3 \n",
      "(Note the sparseness!)\n",
      "\n",
      "flames\n"
     ]
    }
   ],
   "source": [
    "n=10000\n",
    "print(\"First row, first {} entries:\\n{} \".format(n, X_train_counts[0,0:n]))\n",
    "print(\"(Note the sparseness!)\")\n",
    "#print(word, count_vect.vocabulary_[230])\n",
    "print()\n",
    "names = count_vect.get_feature_names()\n",
    "print(names[8696])\n",
    "#get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, use tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: Longer documents may have higher counts of words than shorter ones, just due to length. Therefore, frequencies (count of word divided by total word count) are better. These are term frequencies (`tf`). \n",
    "\n",
    "Furthermore, we can downscale the terms which are seen in most of the documents, since these terms are less useful in differentiating the documents. Inverse Document Frequency -> IDF\n",
    "\n",
    "= `tf_idf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1064, 21366)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# First use 'fit' to to create the estimator\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "# Then transform the data into the matrix representation\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1064, 21366)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or combine both steps at once: \n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a nice vector representation of all sample documents, lets apply a classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Naive Bayes Multi classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Fit to our training data\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is trained on the following categories: \n",
      "['alt.atheism', 'comp.graphics']\n",
      "\n",
      "God is love                    ->                    alt.atheism\n",
      "OpenGL on the GPU is fast      ->                  comp.graphics\n",
      "The fish is in the kitchen     ->                    alt.atheism\n",
      "Satan is my master             ->                    alt.atheism\n",
      "Richard Dawkins                ->                  comp.graphics\n",
      "Science and statistics         ->                  comp.graphics\n"
     ]
    }
   ],
   "source": [
    "docs_short = ['God is love', \n",
    "            'OpenGL on the GPU is fast',\n",
    "           'The fish is in the kitchen',\n",
    "           'Satan is my master',\n",
    "           'Richard Dawkins',\n",
    "            'Science and statistics',\n",
    "           ]\n",
    "\n",
    "docs_long =            [\"\"\"\n",
    "            A preeminent scientist -- and the world's most prominent atheist -- asserts the irrationality of belief in God and the grievous harm religion has inflicted on society, from the Crusades to 9/11.\n",
    "\n",
    "With rigor and wit, Dawkins examines God in all his forms, from the sex-obsessed tyrant of the Old Testament to the more benign (but still illogical) Celestial Watchmaker favored by some Enlightenment thinkers. He eviscerates the major arguments for religion and demonstrates the supreme improbability of a supreme being. He shows how religion fuels war, foments bigotry, and abuses children, buttressing his points with historical and contemporary evidence. The God Delusion makes a compelling case that belief in God is not just wrong but potentially deadly. It also offers exhilarating insight into the advantages of atheism to the individual and society, not the least of which is a clearer, truer appreciation of the universe's wonders than any faith could ever muster.\"\"\",\n",
    "\n",
    "\"\"\"\n",
    "A preeminent scientist -- and the world s most prominent atheist -- asserts the irrationality of belief in science and the grievous harm religion has inflicted on society, from the Crusades to 9/11.\n",
    "With rigor and wit, Dawkins examines science in all his forms, from the sex-obsessed tyrant of the Old Testament to the more benign (but still illogical) Celestial Watchmaker favored by some Enlightenment thinkers. He eviscerates the major arguments for religion and demonstrates the supreme improbability of a supreme being. He shows how religion fuels war, foments bigotry, and abuses children, buttressing his points with historical and contemporary evidence. The science Delusion makes a compelling case that belief in science is not just wrong but potentially deadly. It also offers exhilarating insight into the advantages of atheism to the individual and society, not the least of which is a clearer, truer appreciation of the universe's wonders than any faith could ever muster.\"\"\",\n",
    "           ]\n",
    "\n",
    "docs_mine = docs_short\n",
    "           \n",
    "X_new_counts = count_vect.transform(docs_mine)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "# clf is Classifier\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "print(\"Data is trained on the following categories: \\n{}\".format(categories))\n",
    "print()\n",
    "for doc, category in zip(docs_mine, predicted):\n",
    "    #print('%r => %s' % (doc, twenty_train.target_names[category]))\n",
    "    print(\"{:<30} -> {:>30}\".format(doc,twenty_train.target_names[category]))\n",
    "    \n",
    "#'God is love' => soc.religion.christian\n",
    "#'OpenGL on the GPU is fast' => comp.graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf_piped = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "                     ])\n",
    "print(text_clf_piped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_piped.fit(twenty_train.data, twenty_train.target)  \n",
    "#Pipeline(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, get the rest data\n",
    "twenty_test = fetch_20newsgroups(subset='test',\n",
    "    categories=categories, shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.0%\n"
     ]
    }
   ],
   "source": [
    "# Then make a prediction\n",
    "predicted = text_clf_piped.predict(docs_test)\n",
    "acc = np.mean(predicted == twenty_test.target)          \n",
    "print(\"Accuracy: {:0.1%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.6%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, random_state=42,\n",
    "                                           max_iter=5, tol=None)),\n",
    "])\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)  \n",
    "predicted = text_clf.predict(docs_test)\n",
    "acc = np.mean(predicted == twenty_test.target)          \n",
    "print(\"Accuracy: {:0.1%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "  alt.atheism       0.99      0.96      0.97       319\n",
      "comp.graphics       0.97      0.99      0.98       389\n",
      "\n",
      "  avg / total       0.98      0.98      0.98       708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[306  13]\n",
      " [  4 385]]\n"
     ]
    }
   ],
   "source": [
    "this_CM = metrics.confusion_matrix(twenty_test.target, predicted)\n",
    "print(this_CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alt.atheism</th>\n",
       "      <th>comp.graphics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alt.atheism</th>\n",
       "      <td>306</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics</th>\n",
       "      <td>4</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               alt.atheism  comp.graphics\n",
       "alt.atheism            306             13\n",
       "comp.graphics            4            385"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(this_CM,columns = categories, index = categories )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip...ty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False))])\n",
      "Accuracy: 97.6%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf_SGD_piped = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)),\n",
    "])\n",
    "\n",
    "print(text_clf_SGD_piped)\n",
    "\n",
    "\n",
    "text_clf_SGD_piped.fit(twenty_train.data, twenty_train.target)  \n",
    "predicted = text_clf_SGD_piped.predict(docs_test)\n",
    "acc = np.mean(predicted == twenty_test.target)          \n",
    "print(\"Accuracy: {:0.1%}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip...',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "tfidf__smooth_idf\n",
      "clf__degree\n",
      "clf__decision_function_shape\n",
      "vect__dtype\n",
      "clf__kernel\n",
      "vect__decode_error\n",
      "clf__class_weight\n",
      "vect__max_df\n",
      "vect\n",
      "clf__shrinking\n",
      "clf__verbose\n",
      "clf\n",
      "vect__input\n",
      "clf__cache_size\n",
      "vect__lowercase\n",
      "clf__max_iter\n",
      "clf__tol\n",
      "clf__gamma\n",
      "tfidf__sublinear_tf\n",
      "tfidf__norm\n",
      "vect__encoding\n",
      "clf__random_state\n",
      "vect__max_features\n",
      "tfidf\n",
      "vect__binary\n",
      "vect__stop_words\n",
      "tfidf__use_idf\n",
      "vect__token_pattern\n",
      "memory\n",
      "vect__strip_accents\n",
      "steps\n",
      "vect__preprocessor\n",
      "clf__probability\n",
      "clf__coef0\n",
      "vect__tokenizer\n",
      "vect__analyzer\n",
      "vect__vocabulary\n",
      "clf__C\n",
      "vect__ngram_range\n",
      "vect__min_df\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "my_SVC = sklearn.svm.SVC(C=1.0, \n",
    "                kernel='rbf',\n",
    "                degree=3, \n",
    "                gamma=1, # auto - Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’. If gamma is ‘auto’ then 1/n_features will be used instead.\n",
    "                coef0=0.0, \n",
    "                shrinking=True, \n",
    "                probability=True, # False - Whether to enable probability estimates. This must be enabled prior to calling fit, and will slow down that method.\n",
    "                tol=0.001, \n",
    "                cache_size=200, \n",
    "                class_weight=None, \n",
    "                verbose=False, # False\n",
    "                max_iter=-1, \n",
    "                decision_function_shape='ovr', \n",
    "                random_state=None)\n",
    "\n",
    "text_clf_SVC_piped = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', my_SVC),\n",
    "])\n",
    "\n",
    "print(text_clf_SVC_piped)\n",
    "for param in text_clf_SVC_piped.get_params():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "text_clf_SVC_piped.fit(twenty_train.data, twenty_train.target)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.8%\n",
      "[[  5.66441125e-01   4.33558875e-01]\n",
      " [  1.76658148e-02   9.82334185e-01]\n",
      " [  9.99992782e-01   7.21810630e-06]\n",
      " ..., \n",
      " [  2.17007882e-06   9.99997830e-01]\n",
      " [  5.81867556e-06   9.99994181e-01]\n",
      " [  2.85675547e-08   9.99999971e-01]] 0.957627118644\n"
     ]
    }
   ],
   "source": [
    "predicted = text_clf_SVC_piped.predict(docs_test)\n",
    "acc = np.mean(predicted == twenty_test.target)       \n",
    "print(\"Accuracy: {:0.1%}\".format(acc))\n",
    "\n",
    "prob = text_clf_SVC_piped.predict_proba(docs_test)\n",
    "\n",
    "acc = np.mean(predicted == twenty_test.target)       \n",
    "\n",
    "print(prob,acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00947431  0.99052569]]\n",
      "[[ 0.00846231  0.99153769]]\n"
     ]
    }
   ],
   "source": [
    "prob = text_clf_SVC_piped.predict_proba(['Richard Dawkins'])\n",
    "print(prob)\n",
    "prob = text_clf_SVC_piped.predict_proba(['asdfasdf asdfasdf asddfsa'])\n",
    "print(prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = text_clf_SVC_piped.predict_proba(['God atheist'])\n",
    "my_int = text_clf_SVC_piped.named_steps['clf'].intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.65781663])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the intercept of the model\n",
    "text_clf_SVC_piped.named_steps['clf'].intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A search consists of:\n",
    "\n",
    "1. an estimator (regressor or classifier such as sklearn.svm.SVC());\n",
    "1. a parameter space;\n",
    "1. a method for searching or sampling candidates;\n",
    "1. a cross-validation scheme; and\n",
    "1. a score function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'clf__gamma': [0.1, 0.01, 0.001, 0.0001]},\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list =  {'clf__gamma': [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   25.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_search = sklearn.model_selection.GridSearchCV(text_clf_SVC_piped, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search.fit(twenty_train.data, twenty_train.target) \n",
    "grid_search.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99248120300751874"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.992\n",
      "Best parameters set:\n",
      "\tclf__gamma: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels]+[5]) # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print(\"    \" + empty_cell,)\n",
    "    for label in labels: \n",
    "        print(\"%{}\".format(columnwidth) % label,)\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{}\".format(columnwidth) % label1,)\n",
    "        for j in range(len(labels)): \n",
    "            cell = \"%{}.1\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell),\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# first generate with specified labels\n",
    "labels = categories\n",
    "ypred = twenty_test.target\n",
    "y = predicted\n",
    "cm = confusion_matrix(ypred, y, labels)\n",
    "\n",
    "# then print it in a pretty way\n",
    "print_cm(cm, labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# text to vector encoder with maximally 1024 dimensions\n",
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_features=1024, stop_words='english')\n",
    "# newgroup (target) to multi-class label\n",
    "label_encoder = sklearn.preprocessing.LabelBinarizer()\n",
    "\n",
    "# linear svc one vs rest classifier\n",
    "clf = sklearn.multiclass.OneVsRestClassifier(sklearn.svm.LinearSVC())\n",
    "\n",
    "# encode emails in design matrix\n",
    "X = vectorizer.fit_transform(train.data)\n",
    "# encode email newgroups in target matrix\n",
    "y = label_encoder.fit_transform(train.target)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# fit soft-margin linear svms to X, y\n",
    "clf.fit(X, y)\n",
    "\n",
    "# generate a classification report for the test data\n",
    "classif_report = sklearn.metrics.classification_report(\n",
    "    label_encoder.transform(test.target),\n",
    "    clf.predict(vectorizer.transform(test.data)),\n",
    "    target_names=train.target_names\n",
    ")\n",
    "\n",
    "print(\"Test-data classification report\")\n",
    "print(classif_report)\n",
    "\n",
    "test_acc = sklearn.metrics.accuracy_score(\n",
    "    label_encoder.transform(test.target),\n",
    "    clf.predict(vectorizer.transform(test.data))\n",
    ")\n",
    "\n",
    "print(\"Test-data overall accuracy\", test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
