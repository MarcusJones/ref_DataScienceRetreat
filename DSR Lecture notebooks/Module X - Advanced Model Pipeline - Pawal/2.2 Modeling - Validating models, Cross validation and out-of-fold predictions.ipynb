{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/bioresponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/*@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "}\n",
       "@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tfont-weight: bold;\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "}\n",
       "@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tfont-style: oblique;\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "}\n",
       "@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tfont-weight: bold;\n",
       "\tfont-style: oblique;\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "}*/\n",
       "\n",
       ".navbar-brand, .current_kernel_logo {display:none}\n",
       ".container {\n",
       "    width:80%;    \n",
       "}\n",
       "\n",
       "h1 {\n",
       "\tfont-family: Helvetica, serif;\n",
       "}\n",
       "h4{\n",
       "\tmargin-top:12px;\n",
       "\tmargin-bottom: 3px;\n",
       "   }\n",
       "div.text_cell_render{\n",
       "\tfont-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "\tline-height: 145%;\n",
       "\tfont-size: 100%;\n",
       "\twidth:100%;\n",
       "\tmargin-left:auto;\n",
       "\tmargin-right:auto;\n",
       "}\n",
       ".CodeMirror{\n",
       "\t\tfont-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "}\n",
       ".text_cell_render h5 {\n",
       "\tfont-weight: 300;\n",
       "\tfont-size: 22pt;\n",
       "\t/*color: #4057A1;*/\n",
       "\tfont-style: italic;\n",
       "\tmargin-bottom: .5em;\n",
       "\tmargin-top: 0.5em;\n",
       "\tdisplay: block;\n",
       "}\n",
       "\n",
       ".warning{\n",
       "\tcolor: rgb( 240, 20, 20 )\n",
       "\t}   \n",
       "\n",
       "div.spoiler {\n",
       "\tdisplay: none;\n",
       "}\n",
       "\n",
       ".rendered_html code {\n",
       "\tborder: 0;\n",
       "\t/*background-color: #eee;*/\n",
       "\tfont-size: 100%;\n",
       "\tpadding: 1px 2px;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import css_from_file\n",
    "css_from_file('style/style.css')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/batman/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from the file __data/boehringer/(train|test).csv__ from the data folder. \n",
    "\n",
    "The first column is a binary variable that you want to predict. The rest are numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape (3751, 1776)\n",
      "testing data shape (2501, 1776)\n"
     ]
    }
   ],
   "source": [
    "def load(path):\n",
    "    df = pd.read_csv(path)\n",
    "    if \"Activity\" not in df.columns:\n",
    "        df[\"Activity\"] = np.nan\n",
    "    return df.drop(\"Activity\",axis=1), df.Activity\n",
    "    \n",
    "X_tr, y_tr = load(\"data/boehringer/train.csv\")\n",
    "X_te, y_te = load(\"data/boehringer/test.csv\")\n",
    "\n",
    "print(\"training data shape\", X_tr.shape)\n",
    "print(\"testing data shape\", X_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      NaN\n",
       "1      NaN\n",
       "2      NaN\n",
       "3      NaN\n",
       "4      NaN\n",
       "5      NaN\n",
       "6      NaN\n",
       "7      NaN\n",
       "8      NaN\n",
       "9      NaN\n",
       "10     NaN\n",
       "11     NaN\n",
       "12     NaN\n",
       "13     NaN\n",
       "14     NaN\n",
       "15     NaN\n",
       "16     NaN\n",
       "17     NaN\n",
       "18     NaN\n",
       "19     NaN\n",
       "20     NaN\n",
       "21     NaN\n",
       "22     NaN\n",
       "23     NaN\n",
       "24     NaN\n",
       "25     NaN\n",
       "26     NaN\n",
       "27     NaN\n",
       "28     NaN\n",
       "29     NaN\n",
       "        ..\n",
       "2471   NaN\n",
       "2472   NaN\n",
       "2473   NaN\n",
       "2474   NaN\n",
       "2475   NaN\n",
       "2476   NaN\n",
       "2477   NaN\n",
       "2478   NaN\n",
       "2479   NaN\n",
       "2480   NaN\n",
       "2481   NaN\n",
       "2482   NaN\n",
       "2483   NaN\n",
       "2484   NaN\n",
       "2485   NaN\n",
       "2486   NaN\n",
       "2487   NaN\n",
       "2488   NaN\n",
       "2489   NaN\n",
       "2490   NaN\n",
       "2491   NaN\n",
       "2492   NaN\n",
       "2493   NaN\n",
       "2494   NaN\n",
       "2495   NaN\n",
       "2496   NaN\n",
       "2497   NaN\n",
       "2498   NaN\n",
       "2499   NaN\n",
       "2500   NaN\n",
       "Name: Activity, Length: 2501, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>D10</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>0.243144</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>0.106480</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209791</td>\n",
       "      <td>0.610350</td>\n",
       "      <td>0.356453</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.679051</td>\n",
       "      <td>0.352308</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.235606</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>0.208989</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.517794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.781422</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.303809</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>0.125177</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1776 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         D1        D2    D3   D4        D5        D6        D7        D8  \\\n",
       "0  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166  0.585445   \n",
       "1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105  0.411754   \n",
       "2  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453  0.517720   \n",
       "3  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606  0.288764   \n",
       "4  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361  0.303809   \n",
       "\n",
       "         D9       D10  ...    D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.743663  0.243144  ...        0      0      0      0      0      0      0   \n",
       "1  0.836582  0.106480  ...        1      1      1      1      0      1      0   \n",
       "2  0.679051  0.352308  ...        0      0      0      0      0      0      0   \n",
       "3  0.805110  0.208989  ...        0      0      0      0      0      0      0   \n",
       "4  0.812646  0.125177  ...        0      0      0      0      0      0      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 1776 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>D10</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.076948</td>\n",
       "      <td>0.592436</td>\n",
       "      <td>0.068142</td>\n",
       "      <td>0.038990</td>\n",
       "      <td>0.212112</td>\n",
       "      <td>0.686653</td>\n",
       "      <td>0.274713</td>\n",
       "      <td>0.455133</td>\n",
       "      <td>0.749517</td>\n",
       "      <td>0.270411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026926</td>\n",
       "      <td>0.014663</td>\n",
       "      <td>0.013863</td>\n",
       "      <td>0.021861</td>\n",
       "      <td>0.015196</td>\n",
       "      <td>0.016796</td>\n",
       "      <td>0.012263</td>\n",
       "      <td>0.011730</td>\n",
       "      <td>0.020261</td>\n",
       "      <td>0.011197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.079989</td>\n",
       "      <td>0.105860</td>\n",
       "      <td>0.078414</td>\n",
       "      <td>0.115885</td>\n",
       "      <td>0.102592</td>\n",
       "      <td>0.078702</td>\n",
       "      <td>0.090017</td>\n",
       "      <td>0.162731</td>\n",
       "      <td>0.071702</td>\n",
       "      <td>0.096128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161889</td>\n",
       "      <td>0.120215</td>\n",
       "      <td>0.116938</td>\n",
       "      <td>0.146249</td>\n",
       "      <td>0.122348</td>\n",
       "      <td>0.128522</td>\n",
       "      <td>0.110074</td>\n",
       "      <td>0.107683</td>\n",
       "      <td>0.140911</td>\n",
       "      <td>0.105236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.137873</td>\n",
       "      <td>0.006130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.275590</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.517811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138118</td>\n",
       "      <td>0.625627</td>\n",
       "      <td>0.207374</td>\n",
       "      <td>0.378062</td>\n",
       "      <td>0.707339</td>\n",
       "      <td>0.194357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.585989</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190926</td>\n",
       "      <td>0.674037</td>\n",
       "      <td>0.277845</td>\n",
       "      <td>0.499942</td>\n",
       "      <td>0.738961</td>\n",
       "      <td>0.284316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.668395</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261726</td>\n",
       "      <td>0.740663</td>\n",
       "      <td>0.335816</td>\n",
       "      <td>0.569962</td>\n",
       "      <td>0.788177</td>\n",
       "      <td>0.344626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964381</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994735</td>\n",
       "      <td>0.790831</td>\n",
       "      <td>0.989870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1776 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                D1           D2           D3           D4           D5  \\\n",
       "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000   \n",
       "mean      0.076948     0.592436     0.068142     0.038990     0.212112   \n",
       "std       0.079989     0.105860     0.078414     0.115885     0.102592   \n",
       "min       0.000000     0.282128     0.000000     0.000000     0.002630   \n",
       "25%       0.033300     0.517811     0.000000     0.000000     0.138118   \n",
       "50%       0.066700     0.585989     0.050000     0.000000     0.190926   \n",
       "75%       0.100000     0.668395     0.100000     0.000000     0.261726   \n",
       "max       1.000000     0.964381     0.950000     1.000000     1.000000   \n",
       "\n",
       "                D6           D7           D8           D9          D10  \\\n",
       "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000   \n",
       "mean      0.686653     0.274713     0.455133     0.749517     0.270411   \n",
       "std       0.078702     0.090017     0.162731     0.071702     0.096128   \n",
       "min       0.137873     0.006130     0.000000     0.275590     0.003040   \n",
       "25%       0.625627     0.207374     0.378062     0.707339     0.194357   \n",
       "50%       0.674037     0.277845     0.499942     0.738961     0.284316   \n",
       "75%       0.740663     0.335816     0.569962     0.788177     0.344626   \n",
       "max       0.994735     0.790831     0.989870     1.000000     1.000000   \n",
       "\n",
       "          ...             D1767        D1768        D1769        D1770  \\\n",
       "count     ...       3751.000000  3751.000000  3751.000000  3751.000000   \n",
       "mean      ...          0.026926     0.014663     0.013863     0.021861   \n",
       "std       ...          0.161889     0.120215     0.116938     0.146249   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "75%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "max       ...          1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             D1771        D1772        D1773        D1774        D1775  \\\n",
       "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000   \n",
       "mean      0.015196     0.016796     0.012263     0.011730     0.020261   \n",
       "std       0.122348     0.128522     0.110074     0.107683     0.140911   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             D1776  \n",
       "count  3751.000000  \n",
       "mean      0.011197  \n",
       "std       0.105236  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 1776 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Activity, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise\n",
    "---------------------\n",
    "\n",
    "Using the starter code below try to improve the solution\n",
    "\n",
    "1. What kind of models you can use?\n",
    "2. Try changing model parameters to get the best cross validation error.\n",
    "3. Use pipeline to transform features before modeling:\n",
    "   - use some feature selection mechanism\n",
    "   - use dimension reduction method (pca, svd, etc)\n",
    "   \n",
    "Tip: It is ok to loop over models and datasets like this.\n",
    "\n",
    "```python\n",
    "for data in [pipeline_1, pipeline_2, pipeline_3]:\n",
    "    for model in [model_1, model_2, model_3]:\n",
    "        # do stuff\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template model, for grid search\n",
    "model_logreg=sk.linear_model.LogisticRegression(\n",
    "    penalty='l2', \n",
    "                   dual=False, \n",
    "                   tol=0.0001, \n",
    "                   C=1.0, \n",
    "                   fit_intercept=True, \n",
    "                   intercept_scaling=1, \n",
    "                   class_weight=None, \n",
    "                   random_state=None, \n",
    "                   solver='liblinear', \n",
    "                   max_iter=100, \n",
    "                   multi_class='ovr', \n",
    "                   verbose=0, \n",
    "                   warm_start=False, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'tol': 0.0001}\n",
      "CPU times: user 38.6 s, sys: 3.66 s, total: 42.3 s\n",
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "# Search over this template for best params\n",
    "%%time\n",
    "C_range = [0.01,0.1,0.5,1,1.5]\n",
    "tol_range = [0.0001,0.001,0.01]\n",
    "clf = GridSearchCV(model_logreg, \n",
    "                   param_grid={\n",
    "                       'C':C_range,\n",
    "                       'tol':tol_range})\n",
    "clf.fit(X_tr,y_tr)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your error is 0.5233482398905319\n",
      "You can still improve :)\n",
      "CPU times: user 1min 36s, sys: 8.3 s, total: 1min 44s\n",
      "Wall time: 32.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "final_model = sk.linear_model.LogisticRegression(\n",
    "                   tol=0.0001, \n",
    "                   C=.1,\n",
    "                )\n",
    "\n",
    "oof_predictions = cross_val_predict(clf, X_tr, y_tr, method=\"predict_proba\")\n",
    "\n",
    "err = log_loss(y_tr, oof_predictions)\n",
    "print(\"Your error is\", err)\n",
    "if err > 0.5:\n",
    "    print(\"You can still improve :)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "# Make the prediction\n",
    "# THIS WON'T WORK SINCE\n",
    "y_pred = model.predict(X_te)\n",
    "score = y_te == y_pred\n",
    "score = model.score(X_te, y_te)\n",
    "sum(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template model, for grid search\n",
    "model_sgd = SGDClassifier(\n",
    "    loss='modified_huber', \n",
    "    penalty='l2', \n",
    "    alpha=0.0001,\n",
    "    l1_ratio=0.15, \n",
    "    fit_intercept=True, \n",
    "    max_iter=None, \n",
    "    tol=None, \n",
    "    shuffle=True, \n",
    "    verbose=0, \n",
    "    epsilon=0.1, \n",
    "    n_jobs=1, \n",
    "    random_state=None, \n",
    "    learning_rate='optimal', \n",
    "    eta0=0.0, \n",
    "    power_t=0.5, \n",
    "    class_weight=None, \n",
    "    warm_start=False, \n",
    "    average=False, \n",
    "    n_iter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00002303e+00, 1.00002072e+01, 1.00001842e+02, 1.00001612e+03,\n",
       "       1.00001382e+04, 1.00001151e+05, 1.00000921e+06, 1.00000691e+07,\n",
       "       1.00000461e+08, 1.00000230e+09, 1.00000000e+10])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_range = np.logspace(0.00001,10,11)\n",
    "alpha_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "# Search over this template for best params%%time\n",
    "#tol_range = [0.0001,0.001,0.01]\n",
    "clf = GridSearchCV(model_sgd, \n",
    "                   param_grid={\n",
    "                       'alpha':alpha_range,\n",
    "                       })\n",
    "clf.fit(X_tr,y_tr)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your error is 7.071740472159056\n",
      "You can still improve :)\n"
     ]
    }
   ],
   "source": [
    "#%%script false\n",
    "#%%time\n",
    "final_model = sk.linear_model.LogisticRegression(\n",
    "                   tol=0.0001, \n",
    "                   C=.1,\n",
    "                )\n",
    "\n",
    "#oof_predictions = cross_val_predict(final_model, X_tr, y_tr, method=\"predict_proba\")\n",
    "oof_predictions = cross_val_predict(clf, X_tr, y_tr)\n",
    "\n",
    "err = log_loss(y_tr, oof_predictions)\n",
    "print(\"Your error is\", err)\n",
    "if err > 0.5:\n",
    "    print(\"You can still improve :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LogisticRegression, BayesianRidge, SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your error is 0.4701962668251781\n",
      "Your error is 0.46964817480586113\n",
      "Your error is 0.47679303774244375\n",
      "Your error is 0.47665307084158576\n",
      "Your error is 0.4691921519395264\n",
      "Your error is 0.4761401275916646\n",
      "Your error is 0.46822251891078803\n",
      "Your error is 0.4677563854744935\n",
      "11.2 s ± 134 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "clf = GridSearchCV(RandomForestClassifier(n_jobs=-1, n_estimators=100), \n",
    "                   param_grid={'max_depth':[5,10,15]})\n",
    "\n",
    "oof_predictions = cross_val_predict(clf, X_tr, y_tr, method=\"predict_proba\")\n",
    "\n",
    "err = log_loss(y_tr, oof_predictions)\n",
    "print(\"Your error is\", err)\n",
    "if err > 0.5:\n",
    "    print(\"You can still improve :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of classifiers \n",
    "\n",
    "<div class='spoiler'>\n",
    "\n",
    "clf1 = RandomForestClassifier(n_estimators=10,n_jobs=-1)\n",
    "clf2 = make_pipeline(PCA(), LogisticRegression())\n",
    "\n",
    "clf3 = make_pipeline(\n",
    "   make_union(\n",
    "       RandomTreesEmbedding(n_estimators=10), \n",
    "       LazyTransformer()\n",
    "   ), \n",
    "   LogisticRegression()\n",
    ")\n",
    "\n",
    "for clf in [clf1,clf2,clf3]:\n",
    "    clf.fit(x,y)\n",
    "    \n",
    "clf = make_pipeline(make_union(make_pipeline(RandomTreesEmbedding(n_estimators=20), StandardScaler(with_mean=False)), \n",
    "                               make_pipeline(StandardScaler(with_mean=False), VarianceThreshold(0.1))),\n",
    "                    MLPClassifier((15,), alpha=15.0, verbose=True))\n",
    "\n",
    "clf = BaggingClassifier(make_pipeline(\n",
    "                        make_union(RandomTreesEmbedding(n_estimators=10), \n",
    "                                   LazyTransformer()),\n",
    "                        StandardScaler(with_mean=False), \n",
    "                        VarianceThreshold(0.001),\n",
    "                        MLPClassifier((25,), alpha=10.0, verbose=False)), \n",
    "                        max_samples=0.75,\n",
    "                        max_features=0.75,\n",
    "                        n_estimators=10)\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
