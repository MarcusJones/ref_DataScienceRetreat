{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/*@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "}\n",
       "@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tfont-weight: bold;\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "}\n",
       "@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tfont-style: oblique;\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "}\n",
       "@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tfont-weight: bold;\n",
       "\tfont-style: oblique;\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "}*/\n",
       "\n",
       ".navbar-brand, .current_kernel_logo {display:none}\n",
       ".container {\n",
       "    width:80%;    \n",
       "}\n",
       "\n",
       "h1 {\n",
       "\tfont-family: Helvetica, serif;\n",
       "}\n",
       "h4{\n",
       "\tmargin-top:12px;\n",
       "\tmargin-bottom: 3px;\n",
       "   }\n",
       "div.text_cell_render{\n",
       "\tfont-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "\tline-height: 145%;\n",
       "\tfont-size: 100%;\n",
       "\twidth:100%;\n",
       "\tmargin-left:auto;\n",
       "\tmargin-right:auto;\n",
       "}\n",
       ".CodeMirror{\n",
       "\t\tfont-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "}\n",
       ".text_cell_render h5 {\n",
       "\tfont-weight: 300;\n",
       "\tfont-size: 22pt;\n",
       "\t/*color: #4057A1;*/\n",
       "\tfont-style: italic;\n",
       "\tmargin-bottom: .5em;\n",
       "\tmargin-top: 0.5em;\n",
       "\tdisplay: block;\n",
       "}\n",
       "\n",
       ".warning{\n",
       "\tcolor: rgb( 240, 20, 20 )\n",
       "\t}   \n",
       "\n",
       "div.spoiler {\n",
       "\tdisplay: none;\n",
       "}\n",
       "\n",
       ".rendered_html code {\n",
       "\tborder: 0;\n",
       "\t/*background-color: #eee;*/\n",
       "\tfont-size: 100%;\n",
       "\tpadding: 1px 2px;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import css_from_file\n",
    "css_from_file('style/style.css')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape (3751, 1776)\n",
      "testing data shape (2501, 1776)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def load(path):\n",
    "    df = pd.read_csv(path)\n",
    "    if \"Activity\" not in df.columns:\n",
    "        df[\"Activity\"] = np.nan\n",
    "    return df.drop(\"Activity\",axis=1), df.Activity\n",
    "    \n",
    "X_tr, y_tr = load(\"data/boehringer/train.csv\")\n",
    "X_te, y_te = load(\"data/boehringer/test.csv\")\n",
    "\n",
    "print(\"training data shape\", X_tr.shape)\n",
    "print(\"testing data shape\", X_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking\n",
    "---------------------------\n",
    "\n",
    "In general stacking is a method of blending the models where you treat the predictions from 1 set of models as features for another model. You can think about comittee of experts. In time you are learning who to listen to.\n",
    "\n",
    "In previous exercise we used a very simple way to combine models together.\n",
    "We used a linear combination of predictions\n",
    "\n",
    "There is an excellent article about ensembling here: http://mlwave.com/kaggle-ensembling-guide/\n",
    "\n",
    "Another great source of information: https://www.kaggle.com/c/otto-group-product-classification-challenge/forums/t/14335/1st-place-winner-solution-gilberto-titericz-stanislav-semenov - here you can see stacking in action\n",
    "\n",
    "Exercise\n",
    "----------------------\n",
    "\n",
    "1. Read code below and understand what it does?\n",
    "2. Try to use your classifier from the previous exercise? Does stacking improve a simple average?\n",
    "3. Try other `mixer` models.\n",
    "4. After fitting LogisticRegression mixer look at the `coef_` parameter. Which model has the highest weight?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'bincount'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cea3fafab0e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# DOES NOT WORK ERROR!!!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#from sklearn.cross_validation import cross_val_apply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_apply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Pawal Pipeline notebooks /cross_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbincount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m __all__ = ['KFold',\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'bincount'"
     ]
    }
   ],
   "source": [
    "from stacked_classifier import StackedClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "\n",
    "# DOES NOT WORK ERROR!!!!!\n",
    "#from sklearn.cross_validation import cross_val_apply\n",
    "from cross_validation import cross_val_apply\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import BaggingClassifier, RandomTreesEmbedding, ExtraTreesClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clfs = [\n",
    "]\n",
    "\n",
    "\n",
    "stacked_classifier = StackedClassifier(estimators=clfs,\n",
    "                                       mixer=SGDClassifier(loss='log'),\n",
    "                                       cv=3,\n",
    "                                       n_jobs=-1,\n",
    "                                       probability=True)\n",
    "\n",
    "oof_predictions = cross_val_apply(stacked_classifier,\n",
    "                                  X_tr,\n",
    "                                  y_tr,\n",
    "                                  cv=4,\n",
    "                                  n_jobs=-1, \n",
    "                                  decision_func=\"predict_proba\")\n",
    "\n",
    "err = log_loss(y_tr, oof_predictions)\n",
    "print(\"Your error is\", err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double click to see the answers\n",
    "\n",
    "<div class=\"spoiler\">\n",
    "from stacked_classifier import StackedClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from cross_validation import cross_val_apply\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import BaggingClassifier, RandomTreesEmbedding, ExtraTreesClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "class LazyTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        return x\n",
    "\n",
    "nn_forest = BaggingClassifier(make_pipeline(\n",
    "                        make_union(RandomTreesEmbedding(n_estimators=10), \n",
    "                                   LazyTransformer()),\n",
    "                        StandardScaler(with_mean=False), \n",
    "                        VarianceThreshold(0.001),\n",
    "                        MLPClassifier((25,), alpha=10.0, verbose=False)), \n",
    "                        max_samples=0.75,\n",
    "                        max_features=0.75,\n",
    "                        n_estimators=10)\n",
    "\n",
    "clfs = [\n",
    "    ('nn_forest', nn_forest),\n",
    "    ('rf',RandomForestClassifier(n_estimators=100,n_jobs=1)),\n",
    "    ('rf_entropy',RandomForestClassifier(n_estimators=200, n_jobs=-1, criterion='entropy', max_depth=20, \n",
    "                                 min_samples_split=2, min_samples_leaf=1, max_features=250, \n",
    "                                 max_leaf_nodes=300, bootstrap=True, \n",
    "                                 oob_score=False, random_state=123, \n",
    "                                 verbose=0, warm_start=False, class_weight=None)),\n",
    "    ('rf_entropy_3', RandomForestClassifier(n_estimators=300,n_jobs=-1, criterion = 'entropy', max_depth = 50,\n",
    "                                 max_features = 350, random_state = 123)),\n",
    "    ('rf_3', RandomForestClassifier(min_samples_leaf = 2, min_samples_split = 4, n_estimators = 200)),\n",
    "    ('xgb_1', XGBClassifier(n_estimators=200, max_depth=6)),\n",
    "    ('xgb_2', XGBClassifier(n_estimators=200, max_depth=6, min_child_weight=5)),\n",
    "    ('bag', BaggingClassifier(n_estimators=100)),\n",
    "    ('svc', make_pipeline(StandardScaler(), SVC(probability=True))\n",
    "]\n",
    "\n",
    "clfs = [est for _, est in clfs]\n",
    "\n",
    "stacked_classifier = StackedClassifier(estimators=clfs,\n",
    "                                       mixer=ExtraTreesClassifier(),\n",
    "                                       cv=3,\n",
    "                                       n_jobs=-1,\n",
    "                                       probability=True)\n",
    "\n",
    "oof_predictions = cross_val_apply(stacked_classifier,\n",
    "                                  X_tr,\n",
    "                                  y_tr,\n",
    "                                  cv=4,\n",
    "                                  n_jobs=-1, \n",
    "                                  decision_func=\"predict_proba\")\n",
    "\n",
    "err = log_loss(y_tr, oof_predictions)\n",
    "print(\"Your error is\", err)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
