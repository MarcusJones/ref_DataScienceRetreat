{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations with Spark ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEE\n",
    "https://datasciencemadesimpler.wordpress.com/tag/alternating-least-squares/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext(\"local[*]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "from pyspark.mllib.recommendation import Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.mllib.recommendation.ALS'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        module\n",
       "\u001b[0;31mString form:\u001b[0m <module 'pyspark.mllib' from '/home/batman/miniconda3/envs/spark/lib/python3.6/site-packages/pyspark/mllib/__init__.py'>\n",
       "\u001b[0;31mFile:\u001b[0m        ~/miniconda3/envs/spark/lib/python3.6/site-packages/pyspark/mllib/__init__.py\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "RDD-based machine learning APIs for Python (in maintenance mode).\n",
       "\n",
       "The `pyspark.mllib` package is in maintenance mode as of the Spark 2.0.0 release to encourage\n",
       "migration to the DataFrame-based APIs under the `pyspark.ml` package.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(ALS)\n",
    "#for i in dir(ALS):\n",
    "#    print(i)\n",
    "#?ALS\n",
    "#?Rating\n",
    "?pyspark.mllib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expand_user(a, user):\n",
    "    return [Rating(user, item, ranking) for item, ranking in enumerate(a) if ranking != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expand_all(a):\n",
    "    return [expand_user(items, user) for user, items in enumerate(a)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we have ratings from eight users for six different movies: Titanic, Dirty Dancing, Die Hard, Terminator 2, Wayne's World, and Zoolander. Or in other words, two romantic films, two action films, and two comedies. Each row is a user, each column is a movie.\n",
    "\n",
    "### The ratings are constructed so that if a user has seen both movies in one of these pairs, their ratings for the two movies are similar.\n",
    "\n",
    "### There is no evidence in this data that anyone likes all three film genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5\n",
       "0  5  5  0  0  0  0\n",
       "1  0  0  5  5  0  0\n",
       "2  0  0  0  0  5  5\n",
       "3  0  1  5  5  5  0\n",
       "4  1  1  5  0  5  5\n",
       "5  5  5  0  5  1  1\n",
       "6  5  0  0  5  0  1\n",
       "7  5  5  5  0  1  0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata = [\n",
    "    [5,5,0,0,0,0],\n",
    "    [0,0,5,5,0,0],\n",
    "    [0,0,0,0,5,5],\n",
    "    [0,1,5,5,5,0],\n",
    "    [1,1,5,0,5,5],\n",
    "    [5,5,0,5,1,1],\n",
    "    [5,0,0,5,0,1],\n",
    "    [5,5,5,0,1,0]\n",
    "    ]\n",
    "list_of_ratings = expand_all(rawdata)\n",
    "pd.DataFrame(rawdata)\n",
    "# User 2 has comedy as pref\n",
    "# SImilar to U4 = Prod 2 ; U3 = Prod 2,3 ; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=0, product=0, rating=5.0),\n",
       " Rating(user=0, product=1, rating=5.0),\n",
       " Rating(user=1, product=2, rating=5.0),\n",
       " Rating(user=1, product=3, rating=5.0),\n",
       " Rating(user=2, product=4, rating=5.0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct an RDD of Ratings for every non-zero rating\n",
    "ratings = [val for sublist in list_of_ratings for val in sublist]\n",
    "ratingsRDD = sc.parallelize(ratings)\n",
    "ratingsRDD.take(5)\n",
    "#ratingsRDD.top\n",
    "#ratingsRDD.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.mllib.recommendation.MatrixFactorizationModel object at 0x7f7d44854198> <class 'pyspark.mllib.recommendation.MatrixFactorizationModel'>\n",
      "__class__\n",
      "__del__\n",
      "__delattr__\n",
      "__dict__\n",
      "__dir__\n",
      "__doc__\n",
      "__eq__\n",
      "__format__\n",
      "__ge__\n",
      "__getattribute__\n",
      "__gt__\n",
      "__hash__\n",
      "__init__\n",
      "__init_subclass__\n",
      "__le__\n",
      "__lt__\n",
      "__module__\n",
      "__ne__\n",
      "__new__\n",
      "__reduce__\n",
      "__reduce_ex__\n",
      "__repr__\n",
      "__setattr__\n",
      "__sizeof__\n",
      "__str__\n",
      "__subclasshook__\n",
      "__weakref__\n",
      "_java_loader_class\n",
      "_java_model\n",
      "_load_java\n",
      "_sc\n",
      "call\n",
      "load\n",
      "predict\n",
      "predictAll\n",
      "productFeatures\n",
      "rank\n",
      "recommendProducts\n",
      "recommendProductsForUsers\n",
      "recommendUsers\n",
      "recommendUsersForProducts\n",
      "save\n",
      "userFeatures\n"
     ]
    }
   ],
   "source": [
    "rank = 2\n",
    "numIterations = 5\n",
    "als_lambda = 0.1\n",
    "#als_lambda = 0.0\n",
    "model = ALS.train(ratingsRDD, rank, numIterations, als_lambda, seed=4242, nonnegative=True)\n",
    "print(model, type(model))\n",
    "# there is also a trainImplicit method that one uses when\n",
    "# working with implicit ratings (it uses a different cost function)\n",
    "for i in dir(model):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user       vec\n",
      "0          array('d', [0.0, 2.1502060890197754])\n",
      "1          array('d', [1.0264124870300293, 1.3004276752471924])\n",
      "2          array('d', [1.7977725267410278, 0.3288046419620514])\n",
      "3          array('d', [1.7840503454208374, 0.5924637913703918])\n",
      "4          array('d', [1.7749810218811035, 0.48281174898147583])\n",
      "5          array('d', [0.0, 2.101982355117798])\n",
      "6          array('d', [0.015697011724114418, 2.0789928436279297])\n",
      "7          array('d', [0.03723369538784027, 2.14143443107605])\n"
     ]
    }
   ],
   "source": [
    "# here we see the model's vector of features for each user\n",
    "users = model.userFeatures().collect()\n",
    "res = sorted(users, key=lambda x: x[0])\n",
    "print(\"{:<10} {}\".format('user','vec'))\n",
    "vecs = list()\n",
    "for u,vec in res:\n",
    "    print(\"{:<10} {}\".format(u,vec))\n",
    "    #print(type(vec))\n",
    "    vecs.append(list(vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vecs)\n",
    "# import matplotlib as mpl\n",
    "\n",
    "# mpl.pyplot.plot(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product    vec\n",
      "0          array('d', [0.0, 2.311056137084961])\n",
      "1          array('d', [0.0, 2.25119948387146])\n",
      "2          array('d', [2.04840087890625, 2.214982032775879])\n",
      "3          array('d', [1.8011021614074707, 2.3505852222442627])\n",
      "4          array('d', [2.655724287033081, 0.4831928014755249])\n",
      "5          array('d', [2.6537837982177734, 0.48782041668891907])\n"
     ]
    }
   ],
   "source": [
    "# and the features for the \"products\"\n",
    "products = model.productFeatures().collect()\n",
    "res = sorted(products, key=lambda x: x[0])\n",
    "print(\"{:<10} {}\".format('product','vec'))\n",
    "for u,vec in res:\n",
    "    print(\"{:<10} {}\".format(u,vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=2, product=4, rating=4.933264197914777),\n",
       " Rating(user=2, product=5, rating=4.931297221797547),\n",
       " Rating(user=2, product=2, rating=4.410855198089081)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recommend 3 items for user 2\n",
    "model.recommendProducts(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the original matrix side-by-side with the reconstructed matrix. The values that were originally non-zero should be closely approximated, and the values that were zero (empty) now have predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " original      reconstructed\n",
      "5 5 0 0 0 0     5 5 5 5 1 1  \n",
      "0 0 5 5 0 0     3 3 5 5 3 3  \n",
      "0 0 0 0 5 5     1 1 4 4 5 5  \n",
      "0 1 5 5 5 0     1 1 5 5 5 5  \n",
      "1 1 5 0 5 5     1 1 5 4 5 5  \n",
      "5 5 0 5 1 1     5 5 5 5 1 1  \n",
      "5 0 0 5 0 1     5 5 5 5 1 1  \n",
      "5 5 5 0 1 0     5 5 5 5 1 1  \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\" original      reconstructed\")\n",
    "for user in range(0, len(rawdata)):\n",
    "    for product in range (0, len(rawdata[0])):\n",
    "        sys.stdout.write(\"%d \" % rawdata[user][product])\n",
    "    sys.stdout.write(\"    \")\n",
    "    for product in range (0, len(rawdata[0])):\n",
    "        sys.stdout.write(\"%0.0f \" % model.predict(user, product))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " original         errors        predictions\n",
      "5 5 0 0 0 0     - - - - - -     - - 5 5 1 1  \n",
      "0 0 5 5 0 0     - - - - - -     3 3 - - 3 3  \n",
      "0 0 0 0 5 5     - - - - - -     1 1 4 4 - -  \n",
      "0 1 5 5 5 0     - - - - - -     1 - - - - 5  \n",
      "1 1 5 0 5 5     - - - - - -     - - - 4 - -  \n",
      "5 5 0 5 1 1     - - - - - -     - - 5 - - -  \n",
      "5 0 0 5 0 1     - - - - - -     - 5 5 - 1 -  \n",
      "5 5 5 0 1 0     - - - - - -     - - - 5 - 1  \n"
     ]
    }
   ],
   "source": [
    "print(\" original         errors        predictions\")\n",
    "for user in range(0, len(rawdata)):\n",
    "    \n",
    "    # Original \n",
    "    for product in range (0, len(rawdata[0])):\n",
    "        sys.stdout.write(\"%d \" % rawdata[user][product])\n",
    "    sys.stdout.write(\"    \")\n",
    "    \n",
    "    # Errors \n",
    "    for product in range (0, len(rawdata[0])):\n",
    "        if rawdata[user][product] != 0:\n",
    "            prediction = model.predict(user, product)\n",
    "            if rawdata[user][product] != round(prediction, 0):\n",
    "                sys.stdout.write(\"%0.0f \" % prediction)\n",
    "            else:\n",
    "                sys.stdout.write(\"- \")\n",
    "        else:\n",
    "            sys.stdout.write(\"- \")\n",
    "    sys.stdout.write(\"    \")\n",
    "    \n",
    "    # Predictions\n",
    "    for product in range (0, len(rawdata[0])):\n",
    "        if rawdata[user][product] == 0:\n",
    "            prediction = model.predict(user, product)\n",
    "            sys.stdout.write(\"%0.0f \" % prediction)\n",
    "        else:\n",
    "            sys.stdout.write(\"- \")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the mean squared error of the reconstructed matrix. This can be used to decide if the rank is sufficiently large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (0, 1), (1, 2), (1, 3), (2, 4)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalRDD = ratingsRDD.map(lambda p: (p[0], p[1]))\n",
    "evalRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 0), 4.969246978026604),\n",
       " ((0, 1), 4.840542837818589),\n",
       " ((1, 2), 4.982928176149699),\n",
       " ((1, 3), 4.905439824918915),\n",
       " ((2, 4), 4.933264197914777)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predictAll(evalRDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "predictions.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((4, 2), (5.0, 4.705292034470233)),\n",
       " ((5, 1), (5.0, 4.731981592948102)),\n",
       " ((4, 5), (5.0, 4.945941306582549)),\n",
       " ((3, 1), (1.0, 1.3337541813455545)),\n",
       " ((4, 4), (5.0, 4.9471513704081005))]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsAndPreds = ratingsRDD.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "ratingsAndPreds.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0243250136568209"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a larger dataset we would separate the rating data into training and test sets, and see how well our predicted ratings match the actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "How does lambda affect the results?\n",
    "\n",
    "* try setting lambda to 0.01 (this is the default in some versions of spark)\n",
    "* can you get good results? what if you increase the rank?\n",
    "\n",
    "What happens as you increase (or decrease) the rank?\n",
    "\n",
    "How sensitive are the results to the random seed?\n",
    "\n",
    "What would happen if one movie was universally loved, or hated?\n",
    "\n",
    "What happens if you remove some of the rating data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark)\n",
   "language": "python",
   "name": "spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
