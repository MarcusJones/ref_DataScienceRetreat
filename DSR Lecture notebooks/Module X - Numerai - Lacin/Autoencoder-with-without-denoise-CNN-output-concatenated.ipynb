{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import random\n",
    "random.seed(11)\n",
    "import numpy as np\n",
    "np.random.seed(11)\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(11)\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "from model import Model\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_integer('numepochs', 30, \"\")\n",
    "tf.app.flags.DEFINE_integer('batchsize', 256, \"\")\n",
    "tf.app.flags.DEFINE_boolean('denoise', True, \"\")\n",
    "\n",
    "datadir='/home/lacin/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to = np.load('../../../tourwithcnn50w_100col.npy')\n",
    "tr = np.load('../../../trainwithcnn50w_100col.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "va=to[0:73865]\n",
    "te=to[73865:-6798]\n",
    "li=to[-6798:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6798, 100), (73865, 100), (268163, 100), (535663, 100))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li.shape,va.shape,te.shape,tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tour = pd.read_csv( datadir + 'numerai_tournament_data.csv')   \n",
    "df_train = pd.read_csv( datadir + 'numerai_training_data.csv')\n",
    "df_valid = tour[tour['data_type'].isin(['validation'])]\n",
    "\n",
    "df_live = tour[tour['data_type'].isin(['live'])]\n",
    "df_test = tour[tour['data_type'].isin(['test'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train=df_train[50:] #window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((535663, 54), (73865, 54), (268163, 54), (6798, 54))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape, df_test.shape,df_live.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lacin/numerai/models/autoencoder/model.py:81: add_arg_scope.<locals>.func_with_args (from tensorflow.contrib.framework.python.ops.arg_scope) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.add_loss instead.\n",
      "WARNING:tensorflow:From /home/lacin/numerai/models/autoencoder/model.py:83: get_total_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_total_loss instead.\n",
      "WARNING:tensorflow:From /home/lacin/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:261: get_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_losses instead.\n",
      "WARNING:tensorflow:From /home/lacin/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:263: get_regularization_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_regularization_losses instead.\n",
      "WARNING:tensorflow:From /home/lacin/numerai/models/autoencoder/model.py:81: add_arg_scope.<locals>.func_with_args (from tensorflow.contrib.framework.python.ops.arg_scope) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.add_loss instead.\n",
      "WARNING:tensorflow:From /home/lacin/numerai/models/autoencoder/model.py:83: get_total_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_total_loss instead.\n",
      "WARNING:tensorflow:From /home/lacin/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:261: get_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_losses instead.\n",
      "WARNING:tensorflow:From /home/lacin/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:263: get_regularization_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_regularization_losses instead.\n",
      "INFO:tensorflow:Starting standard services.\n",
      "INFO:tensorflow:Saving checkpoint to path logs/1511525534/model.ckpt\n",
      "INFO:tensorflow:Starting queue runners.\n",
      "INFO:tensorflow:model/global_step/sec: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 59988 parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[5] loss (train): 0.00035465, loss (valid): 0.00056429 [best: 0.00056429, wait: 0]:  20%|██        | 6/30 [01:50<07:17, 18.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:model/global_step/sec: 109.676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11] loss (train): 0.00035395, loss (valid): 0.00046685 [best: 0.00045175, wait: 1]:  40%|████      | 12/30 [03:39<05:25, 18.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:model/global_step/sec: 116.308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18] loss (train): 0.00035359, loss (valid): 0.00042092 [best: 0.00041897, wait: 1]:  63%|██████▎   | 19/30 [05:44<03:17, 17.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:model/global_step/sec: 116.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[25] loss (train): 0.00035347, loss (valid): 0.00039464 [best: 0.00039464, wait: 0]:  87%|████████▋ | 26/30 [07:49<01:11, 17.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:model/global_step/sec: 116.916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[29] loss (train): 0.00035370, loss (valid): 0.00037800 [best: 0.00037800, wait: 0]: 100%|██████████| 30/30 [09:01<00:00, 17.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0003779316321015358\n",
      "SavedDEnc\n"
     ]
    }
   ],
   "source": [
    "num_features = tr.shape[1]\n",
    "features = tf.placeholder(tf.float32, shape=[None, num_features], name='features')\n",
    "\n",
    "with tf.variable_scope('model'):\n",
    "    train_model = Model(features, denoise=FLAGS.denoise, is_training=True)\n",
    "\n",
    "with tf.variable_scope('model', reuse=True):\n",
    "    test_model = Model(features, denoise=FLAGS.denoise, is_training=False)\n",
    "\n",
    "best = None\n",
    "wait = 0\n",
    "summary_op = tf.summary.merge_all() #  merge_all_summaries()\n",
    "logdir = 'logs/{}'.format(int(time.time()))\n",
    "supervisor = tf.train.Supervisor(logdir=logdir, summary_op=None)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "with supervisor.managed_session() as sess:\n",
    "    summary_writer = tf.summary.FileWriter(logdir, graph=sess.graph)\n",
    "        \n",
    "    print('Training model with {} parameters...'.format(train_model.num_parameters))\n",
    "    with tqdm(total=FLAGS.numepochs) as pbar:\n",
    "        for epoch in range(FLAGS.numepochs):\n",
    "            X_train_epoch = shuffle(tr)\n",
    "            num_batches = len(X_train_epoch) // FLAGS.batchsize\n",
    "            losses = []\n",
    "            for batch_index in range(num_batches):\n",
    "                batch_start = batch_index * FLAGS.batchsize\n",
    "                batch_end = batch_start + FLAGS.batchsize\n",
    "\n",
    "                X_train_batch = X_train_epoch[batch_start:batch_end]\n",
    "\n",
    "                _, loss = sess.run([\n",
    "                    train_model.train_step,\n",
    "                    train_model.loss,\n",
    "                ], feed_dict={\n",
    "                    features: X_train_batch,\n",
    "                })\n",
    "                losses.append(loss)\n",
    "            loss_train = np.mean(losses)\n",
    "\n",
    "            loss_valid, summary_str = sess.run([\n",
    "                test_model.loss,\n",
    "                summary_op,\n",
    "            ], feed_dict={\n",
    "                features: va,\n",
    "            })\n",
    "            if best is None or loss_valid < best:\n",
    "                best = loss_valid\n",
    "                wait = 0\n",
    "            else:\n",
    "                wait += 1\n",
    "            summary_writer.add_summary(summary_str, epoch)\n",
    "            summary_writer.flush()\n",
    "            pbar.set_description('[{}] loss (train): {:.8f}, loss (valid): {:.8f} [best: {:.8f}, wait: {}]' \\\n",
    "                .format(epoch, loss_train, loss_valid, best, wait))\n",
    "            pbar.update()        \n",
    "\n",
    "    summary_writer.close()\n",
    "    \n",
    "    loss_valid = sess.run(test_model.loss, feed_dict={\n",
    "        features: va,\n",
    "    })\n",
    "    print('Validation loss: {}'.format(loss_valid))\n",
    "    \n",
    "    t_Group_eras = df_train[\"era\"].map(lambda x: int(x[3:])).values\n",
    "    group_kfold = GroupKFold(n_splits=10)\n",
    "    z_train = np.zeros([len(tr),48])    \n",
    "    #tr=tr.values\n",
    "    for f,(train_index, test_index) in enumerate(group_kfold.split(tr, None, t_Group_eras)): \n",
    "                \n",
    "        x_train = tr[test_index]      \n",
    "       \n",
    "        z_train_tmp = sess.run(test_model.z, feed_dict={ features: x_train })\n",
    "        \n",
    "        z_train[test_index] = z_train_tmp    \n",
    "    \n",
    "    v_Group_eras = df_valid[\"era\"].map(lambda x: int(x[3:])).values\n",
    "    group_kfold2 = GroupKFold(n_splits=10)\n",
    "    z_valid = np.zeros([len(va),48])\n",
    "    #va=va.values\n",
    "    for f,(train_index, test_index) in enumerate(group_kfold2.split(va, None, v_Group_eras)): \n",
    "                \n",
    "        x_valid = va[test_index]        \n",
    "        \n",
    "        z_valid_tmp = sess.run(test_model.z, feed_dict={ features: x_valid })\n",
    "        \n",
    "        z_valid[test_index] = z_valid_tmp    \n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    z_test = np.zeros([len(te),48])\n",
    "    #te=te.values\n",
    "    for f,(train_index, test_index) in enumerate(kf.split(te, None, None)): \n",
    "                \n",
    "        x_test = te[test_index]       \n",
    "        \n",
    "        z_test_tmp = sess.run(test_model.z, feed_dict={ features: x_test })\n",
    "        \n",
    "        z_test[test_index] = z_test_tmp    \n",
    "    \n",
    "    z_live = sess.run(test_model.z, feed_dict={ features: li })\n",
    "    \n",
    "    if FLAGS.denoise:\n",
    "        np.savez('./denoisingconcnn50w7f15nf.npz', z_train=z_train, z_valid=z_valid, z_test=z_test, z_live=z_live)\n",
    "        print(\"SavedDEnc\")\n",
    "    else:\n",
    "        np.savez('./autoencoderoncnn50w7f15nf.npz', z_train=z_train, z_valid=z_valid, z_test=z_test, z_live=z_live)\n",
    "        print(\"SavedEnc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
