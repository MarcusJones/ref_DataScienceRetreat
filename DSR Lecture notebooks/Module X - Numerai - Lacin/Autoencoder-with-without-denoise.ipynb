{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT denoising!\n",
      "INFO:tensorflow:Starting standard services.\n",
      "INFO:tensorflow:Saving checkpoint to path logs/1521387893/model.ckpt\n",
      "INFO:tensorflow:Starting queue runners.\n",
      "INFO:tensorflow:model/global_step/sec: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 26386 parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[9] loss (train): 0.00042213, loss (valid): 0.00143754 [best: 0.00131552, wait: 1]:  17%|█▋        | 10/60 [01:59<09:55, 11.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:model/global_step/sec: 128.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19] loss (train): 0.00042000, loss (valid): 0.00099169 [best: 0.00099169, wait: 0]:  33%|███▎      | 20/60 [03:58<07:58, 11.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:model/global_step/sec: 128.633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[29] loss (train): 0.00042097, loss (valid): 0.00071521 [best: 0.00071521, wait: 0]:  50%|█████     | 30/60 [05:57<05:57, 11.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:model/global_step/sec: 129.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[38] loss (train): 0.00042155, loss (valid): 0.00053656 [best: 0.00053656, wait: 0]:  65%|██████▌   | 39/60 [07:47<04:16, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:model/global_step/sec: 125.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[49] loss (train): 0.00042120, loss (valid): 0.00048953 [best: 0.00048092, wait: 3]:  83%|████████▎ | 50/60 [09:58<01:59, 11.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoint to path logs/1521387893/model.ckpt\n",
      "INFO:tensorflow:model/global_step/sec: 128.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[58] loss (train): 0.00042132, loss (valid): 0.00044546 [best: 0.00044197, wait: 4]:  98%|█████████▊| 59/60 [11:48<00:12, 12.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:model/global_step/sec: 126.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[59] loss (train): 0.00042165, loss (valid): 0.00046361 [best: 0.00044197, wait: 5]: 100%|██████████| 60/60 [12:00<00:00, 12.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0004633847565855831\n",
      "SavedEnc\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "import random\n",
    "random.seed(11)\n",
    "import numpy as np\n",
    "np.random.seed(11)\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(11)\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "from model import Model\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_integer('numepochs', 60, \"\")\n",
    "tf.app.flags.DEFINE_integer('batchsize', 256, \"\")\n",
    "tf.app.flags.DEFINE_boolean('denoise', False, \"\")   # compute 2 results\n",
    "\n",
    "if FLAGS.denoise:\n",
    "    print('Denoising!')\n",
    "else:\n",
    "    print('NOT denoising!')\n",
    "\n",
    "datadir= '/home/bogazicili34/Notebooks/24March18/numerai_dataset_99/'\n",
    "\n",
    "tour = pd.read_csv( datadir + 'numerai_tournament_data.csv')   \n",
    "df_train = pd.read_csv( datadir + 'numerai_training_data.csv')\n",
    "df_valid = tour[tour['data_type'].isin(['validation'])]\n",
    "\n",
    "df_live = tour[tour['data_type'].isin(['live'])]\n",
    "df_test = tour[tour['data_type'].isin(['test'])]\n",
    "\n",
    "feature_cols = [f for f in df_train.columns if \"feature\" in f]\n",
    "X_train = df_train[feature_cols].values\n",
    "X_valid = df_valid[feature_cols].values\n",
    "\n",
    "X_test = df_test[feature_cols].values\n",
    "X_live = df_live[feature_cols].values\n",
    "\n",
    "\n",
    "num_features = len(feature_cols)\n",
    "features = tf.placeholder(tf.float32, shape=[None, num_features], name='features')\n",
    "\n",
    "with tf.variable_scope('model'):\n",
    "    train_model = Model(features, denoise=FLAGS.denoise, is_training=True)\n",
    "\n",
    "with tf.variable_scope('model', reuse=True):\n",
    "    test_model = Model(features, denoise=FLAGS.denoise, is_training=False)\n",
    "\n",
    "best = None\n",
    "wait = 0\n",
    "summary_op = tf.summary.merge_all() #  merge_all_summaries()\n",
    "logdir = 'logs/{}'.format(int(time.time()))\n",
    "supervisor = tf.train.Supervisor(logdir=logdir, summary_op=None)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "with supervisor.managed_session() as sess:\n",
    "    summary_writer = tf.summary.FileWriter(logdir, graph=sess.graph)\n",
    "        \n",
    "    print('Training model with {} parameters...'.format(train_model.num_parameters))\n",
    "    with tqdm(total=FLAGS.numepochs) as pbar:\n",
    "        for epoch in range(FLAGS.numepochs):\n",
    "            X_train_epoch = shuffle(X_train)\n",
    "            num_batches = len(X_train_epoch) // FLAGS.batchsize\n",
    "            losses = []\n",
    "            for batch_index in range(num_batches):\n",
    "                batch_start = batch_index * FLAGS.batchsize\n",
    "                batch_end = batch_start + FLAGS.batchsize\n",
    "\n",
    "                X_train_batch = X_train_epoch[batch_start:batch_end]\n",
    "\n",
    "                _, loss = sess.run([\n",
    "                    train_model.train_step,\n",
    "                    train_model.loss,\n",
    "                ], feed_dict={\n",
    "                    features: X_train_batch,\n",
    "                })\n",
    "                losses.append(loss)\n",
    "            loss_train = np.mean(losses)\n",
    "\n",
    "            loss_valid, summary_str = sess.run([\n",
    "                test_model.loss,\n",
    "                summary_op,\n",
    "            ], feed_dict={\n",
    "                features: X_valid,\n",
    "            })\n",
    "            if best is None or loss_valid < best:\n",
    "                best = loss_valid\n",
    "                wait = 0\n",
    "            else:\n",
    "                wait += 1\n",
    "            summary_writer.add_summary(summary_str, epoch)\n",
    "            summary_writer.flush()\n",
    "            pbar.set_description('[{}] loss (train): {:.8f}, loss (valid): {:.8f} [best: {:.8f}, wait: {}]' \\\n",
    "                .format(epoch, loss_train, loss_valid, best, wait))\n",
    "            pbar.update()        \n",
    "\n",
    "    summary_writer.close()\n",
    "    \n",
    "    loss_valid = sess.run(test_model.loss, feed_dict={\n",
    "        features: X_valid,\n",
    "    })\n",
    "    print('Validation loss: {}'.format(loss_valid))\n",
    "    \n",
    "    t_Group_eras = df_train[\"era\"].values\n",
    "    group_kfold = GroupKFold(n_splits=10)\n",
    "    z_train = np.zeros([len(X_train),32])    \n",
    "    for f,(train_index, test_index) in enumerate(group_kfold.split(X_train, None, t_Group_eras)): \n",
    "                \n",
    "        x_train = X_train[test_index]      \n",
    "       \n",
    "        z_train_tmp = sess.run(test_model.z, feed_dict={ features: x_train })\n",
    "        \n",
    "        z_train[test_index] = z_train_tmp    \n",
    "    \n",
    "    v_Group_eras = df_valid[\"era\"].values\n",
    "    group_kfold2 = GroupKFold(n_splits=10)\n",
    "    z_valid = np.zeros([len(X_valid),32])\n",
    "    for f,(train_index, test_index) in enumerate(group_kfold2.split(X_valid, None, v_Group_eras)): \n",
    "                \n",
    "        x_valid = X_valid[test_index]        \n",
    "        \n",
    "        z_valid_tmp = sess.run(test_model.z, feed_dict={ features: x_valid })\n",
    "        \n",
    "        z_valid[test_index] = z_valid_tmp    \n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    z_test = np.zeros([len(X_test),32])\n",
    "    for f,(train_index, test_index) in enumerate(kf.split(X_test, None, None)): \n",
    "                \n",
    "        x_test = X_test[test_index]       \n",
    "        \n",
    "        z_test_tmp = sess.run(test_model.z, feed_dict={ features: x_test })\n",
    "        \n",
    "        z_test[test_index] = z_test_tmp    \n",
    "    \n",
    "    z_live = sess.run(test_model.z, feed_dict={ features: X_live })\n",
    "    \n",
    "    if FLAGS.denoise:\n",
    "        np.savez('./denoising2811.npz', z_train=z_train, z_valid=z_valid, z_test=z_test, z_live=z_live)\n",
    "        print(\"SavedDEnc\")\n",
    "    else:\n",
    "        np.savez('./autoencoder2811.npz', z_train=z_train, z_valid=z_valid, z_test=z_test, z_live=z_live)\n",
    "        print(\"SavedEnc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
