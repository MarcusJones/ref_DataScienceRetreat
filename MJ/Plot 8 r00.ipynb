{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded modules:\n",
      "numpy                np              1.14.0\n",
      "pandas               pd              0.22.0\n",
      "sklearn              sk              0.19.1\n",
      "keras                ks              2.1.4\n",
      "\n",
      "matplotlib           mpl             2.1.2\n",
      "matplotlib.pyplot    plt             N/A\n",
      "matplotlib.image     mpimg           N/A\n",
      "seaborn              sns             0.8.1\n",
      "PIL                  PIL             5.0.0\n",
      "\n",
      "ExergyUtilities      exergy          2.0.\n",
      "\n",
      "pyspark              pyspark         2.2.1\n"
     ]
    }
   ],
   "source": [
    "import os, re, logging, json\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2 #conda install --channel https://conda.anaconda.org/menpo opencv3\n",
    "from datetime import datetime\n",
    "import random\n",
    "import time\n",
    "\n",
    "print_imports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_path = r\"/home/batman/git/ai_drive/src\"\n",
    "sys.path.append(mod_path)\n",
    "logging.debug(\"ADDED TO PATH: \".format(mod_path))\n",
    "import drive.analysis_offline as analysis\n",
    "import drive.my_generators as my_generators\n",
    "import drive.my_plotting as my_plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project path\n",
    "this_project_path = r\"/media/batman/USB STICK\"\n",
    "project_name = r'catdog3'\n",
    "path_root_project = os.path.join(this_project_path,project_name)\n",
    "assert os.path.exists(path_root_project)\n",
    "\n",
    "# Full data\n",
    "path_data_root = r\"/home/batman/Dropbox/DATA/cats_dogs_all_test_split\"\n",
    "path_test = os.path.join(path_data_root, 'my_test')\n",
    "\n",
    "# Test data path\n",
    "path_cats = os.path.join(path_test,'cats')\n",
    "path_dogs = os.path.join(path_test,'dogs')\n",
    "\n",
    "### Constants\n",
    "IMG_SIZE = 150\n",
    "layer_funcs = analysis.LAYER_FUNCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 cats\n",
    "cat_images = os.listdir(path_cats)\n",
    "dog_images = os.listdir(path_dogs)\n",
    "\n",
    "cat_images4 = random.sample(cat_images,4)\n",
    "dog_images4 = random.sample(dog_images,4)\n",
    "\n",
    "images_list = list()\n",
    "images_list = images_list + [(f.split('.')[0], os.path.join(path_cats,f) ) for f in cat_images4]\n",
    "images_list = images_list + [(f.split('.')[0], os.path.join(path_dogs,f) ) for f in dog_images4]\n",
    "\n",
    "images_list = [(count,i[0],i[1]) for count,i in enumerate(images_list)]\n",
    "#images_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the sample of 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cat /home/batman/Dropbox/DATA/cats_dogs_all_test_split/my_test/cats/cat.7973.jpg\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown format code 'f' for object of type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-ae09e498ec3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mproba_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{:.0f}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mpredicted_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown format code 'f' for object of type 'str'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5879585748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(20, 10))\n",
    "columns = 4\n",
    "rows = 2\n",
    "predicted_class = None\n",
    "for count, label, this_path in images_list:\n",
    "    \n",
    "    print(count, label, this_path)\n",
    "    \n",
    "    i = i+1\n",
    "    \n",
    "    img,pred = img_pred\n",
    "    \n",
    "    proba_str = \"{:.0f}%\".format(pred*100)\n",
    "    if pred < 0.5:\n",
    "        predicted_class = 'Cat'\n",
    "    elif pred >= 0.5:\n",
    "        predicted_class = 'Dog'\n",
    "    else:\n",
    "        raise\n",
    "    \n",
    "    \n",
    "    this_ax = fig.add_subplot(rows, columns, i)\n",
    "\n",
    "    label_str =  str(i) + '\\n' + predicted_class + '\\n' + proba_str\n",
    "    \n",
    "    plt.text(150/2, 150/2, label_str, {'ha': 'center', 'va': 'center'}, rotation=45,size=30, color='black')\n",
    "    plt.text(150/2-2, 150/2, label_str, {'ha': 'center', 'va': 'center'}, rotation=45,size=30, color='lime')\n",
    "    #color : color\n",
    "\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root  - 10  - <ipython-input-71-478ec0875eee>  <module>                      : **** RUN run000 ****\n",
      "start; 2018-03-18 17:03:37\n",
      "elapsed; 1042.2\n",
      "generator; my_generators         get_train_generator_simple    : Training\n",
      "root  - 20  - analysis_offline      get_weights                   : Found 12 weights files, total 317 MB = 26.4 MB per file\n",
      "{'Total': 3453121, 'Trainable': 3453121, 'Non-trainable': 0}\n",
      "{'epoch': 24, 'fname': 'weights-epoch24-0.87.hdf5', 'path': '/media/batman/USB STICK/catdog3/run000/weights-epoch24-0.87.hdf5', 'size': 26.384925842285156}\n",
      "0 Conv2D, kernel 3, filters 32\n",
      "1 MaxPooling2D, pool 2\n",
      "2 Conv2D, kernel 3, filters 64\n",
      "3 MaxPooling2D, pool 2\n",
      "4 Conv2D, kernel 3, filters 128\n",
      "5 MaxPooling2D, pool 2\n",
      "6 Conv2D, kernel 3, filters 128\n",
      "7 MaxPooling2D, pool 2\n",
      "8 Flatten\n",
      "9 Dropout, dropout 0.0\n",
      "10 Dense\n",
      "11 Dense\n",
      "/media/batman/USB STICK/catdog3/run000/history run000.txt\n",
      "Epochs 50\n",
      "Steps 400.0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-478ec0875eee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m#my_plotting.plot_hist_dict(hist_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m#del model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "run_folders = [dir for dir in os.listdir(root_path) if re.match('run',dir)]\n",
    "run_folders.sort()\n",
    "\n",
    "# Loop run folders\n",
    "for rfolder in run_folders:\n",
    "    this_run_path = os.path.join(root_path,rfolder)\n",
    "    logging.debug('**** RUN {} ****'.format(rfolder))\n",
    "    \n",
    "    ###### Log file ######\n",
    "    log = analysis.get_log_file(this_run_path)\n",
    "    print('start;',log['start'])\n",
    "    print('elapsed; {:.1f}'.format(log['elapsed'].seconds/60))\n",
    "    print('generator;',log['generator'])\n",
    "    #raise\n",
    "    ###### Weights ######\n",
    "    wts = analysis.get_weights(this_run_path)\n",
    "    if wts: best_wt = wts[-1] # BEST weight (last weight)\n",
    "    \n",
    "    ###### Architecture ######\n",
    "    model = analysis.load_model(this_run_path)\n",
    "    arch_dict = analysis.read_model_json(this_run_path)\n",
    "    \n",
    "    #model.summary()\n",
    "    print(analysis.count_params(model))\n",
    "    \n",
    "    ##### Reload weights #####\n",
    "    if wts:\n",
    "        print(best_wt)\n",
    "        model.load_weights(best_wt['path'])\n",
    "    \n",
    "    #raise\n",
    "    ###### Loop layers ######\n",
    "    for i,layer in enumerate(arch_dict['config']):\n",
    "        layer_str = layer_funcs[layer['class_name']](layer)\n",
    "        print(i,layer_str)\n",
    "\n",
    "    ###### History ######\n",
    "    path_hist = analysis.get_history(this_run_path)    \n",
    "    with open(path_hist) as hist_file:\n",
    "        hist_dict = json.load(hist_file)\n",
    "    print(\"Epochs\",hist_dict['params']['epochs'])\n",
    "    print(\"Steps\",hist_dict['params']['steps'])\n",
    "    \n",
    "    #my_plotting.plot_hist_dict(hist_dict)\n",
    "    #del model\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over the test images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cm = confusion_matrix(y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.preprocessing.image\n",
    "test_datagen_real = ks.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator = test_datagen_real.flow_from_directory(\n",
    "        path_test,\n",
    "        target_size = (150,150),\n",
    "        batch_size = 500,\n",
    "        shuffle=False,\n",
    "        #class_mode = \"binary\",\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation constants\n",
    "num_batches = len(test_generator)\n",
    "num_files = test_generator.n\n",
    "batch_size = test_generator.batch_size\n",
    "\n",
    "# Get filename numbers (indices)\n",
    "fnames = test_generator.filenames\n",
    "nums = [re.search('(?P<num>\\d+).jpg',f).groups()[0]  for f in fnames]\n",
    "nums = [int(n)  for n in nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_files = 0\n",
    "test_generator.reset()\n",
    "predictions_list = list()\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for i,batch in enumerate(test_generator):\n",
    "    # Tally the actual seen images (tensor layers)\n",
    "    seen_files += batch[0].shape[0]\n",
    "    \n",
    "    # Current index\n",
    "    idx = test_generator.batch_index\n",
    "    \n",
    "    # Report\n",
    "    logging.debug(\"{} seen {} / {} = {:.1f}%\".format(idx,seen_files,num_files,seen_files/num_files*100))\n",
    "\n",
    "    # Make predictions and append\n",
    "    predictions = model.predict(batch[0])\n",
    "    predictions = [i[0] for i in predictions]\n",
    "    predictions_list += predictions\n",
    "    \n",
    "    # Seen all batches, break the loop \n",
    "    if i+1 == num_batches:\n",
    "        break\n",
    "\n",
    "t1 = time.time()        \n",
    "logging.debug(\"Processed {} images in {} batches. Elapsed time: {}}\".format(seen_files, num_batches, total = t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(predictions_list) == len(nums)\n",
    "df_test = pd.DataFrame({'predicted probability':predictions_list},index = nums)\n",
    "df_test.sort_index(inplace=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_test) == len(df_solutions)\n",
    "assert (df_test.index == df_solutions.index).all()\n",
    "df_acc = df_solutions.join(df_test)\n",
    "df_acc.dtypes\n",
    "df_acc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission_file.csv','w') as f:\n",
    "    f.write('id,label\\n')\n",
    "            \n",
    "with open('submission_file.csv','a') as f:\n",
    "    for data in tqdm(test_data):\n",
    "        img_num = data[1]\n",
    "        img_data = data[0]\n",
    "        orig = img_data\n",
    "        data = img_data.reshape(IMG_SIZE,IMG_SIZE,1)\n",
    "        model_out = model.predict([data])[0]\n",
    "        f.write('{},{}\\n'.format(img_num,model_out[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #img=mpimg.imread(this_img_path)\n",
    "    \n",
    "    #img = mpimg.open(this_img_path)\n",
    "    #img.load()\n",
    "    \n",
    "    \n",
    "    #img = Image.open(this_img_path)\n",
    "    #img.load()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    this_ax = fig.add_subplot(rows, columns, i)\n",
    "\n",
    "    this_ax.set_title(\"{} {} {}\".format(name, number, img.shape,))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_img_path = random.sample(test_image_paths,1)[0]\n",
    "assert os.path.exists(this_img_path)\n",
    "fname = os.path.split(this_img_path)[-1]\n",
    "name, ext = fname.split(\".\")\n",
    "num = int(name)\n",
    "\n",
    "img=mpimg.imread(this_img_path)\n",
    "#nop = np.array([None])\n",
    "img = img[np.newaxis]\n",
    "print(img.shape)\n",
    "#img = np.append(nop, )\n",
    "#cd_predict(model,img)\n",
    "#model.predict(img, verbose=0)\n",
    "#fit_img = test_datagen.fit(img)\n",
    "fit_img_gen = test_datagen.flow(img)\n",
    "for fit_img in fit_img_gen:\n",
    "    print(fit_img.shape)\n",
    "    model.predict(fit_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = random.sample(test_image_paths,1)\n",
    "for p in sample:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cd_predict(model,img):\n",
    "    print(\"making predictions on test set...\")\n",
    "    predictions = model.predict(img, verbose=0)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_data, test_labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Image\n",
    "#\n",
    "\n",
    "color = (17/255,17/255,17/255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    if predictions[i, 0] >= 0.5: \n",
    "        print('I am {:.2%} sure this is a Dog'.format(predictions[i][0]))\n",
    "    else: \n",
    "        print('I am {:.2%} sure this is a Cat'.format(1-predictions[i][0]))\n",
    "        \n",
    "    plt.imshow(test[i].T)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
